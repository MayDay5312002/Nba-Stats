name: Scrape

on:
  schedule:
    - cron: '0 */1 * * *' # Run every hour
  workflow_dispatch:

env:
  ACTIONS_ALLOW_UNSECURE_COMMANDS: true
  ACTIONS_ALLOW_USE_UNSECURE_NODE_VERSION: true
jobs:
  scrapy_job:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout Repository
      uses: actions/checkout@v2

    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: 3.9  # Specify the Python version you need

    - name: Install Dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt  # Replace with the path to your requirements file

    - name: Run Scrapy Spider
      run: |
        cd ./nbascrapper
        scrapy crawl nbaspider -O ../stat.json  # Replace with the name of your Scrapy spider

    - name: Make Changes
      run: |
        git config user.email "evarretta.luke@gmail.com"
        git config user.name "MayDay5312002"
        git pull
        git status
        git add stat.json
        git commit -m "Updating existing json file"

    - name: Push Changes
      uses: ad-m/github-push-action@v0.6.0
      with:
        github_token: ${{ secrets.GITHUB_TOKEN }}
        branch: main

